{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49452a0e-59a4-4844-9747-b71e2ec452ae",
   "metadata": {},
   "source": [
    "### E2E Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8764835e-1fa1-4ab7-a6e5-c34552103279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 22:59:48.974084: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-18 22:59:49.017026: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-18 22:59:49.017935: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-18 22:59:49.817487: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks, models\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Discretization,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Lambda,\n",
    ")\n",
    "from tensorflow.keras.layers.experimental.preprocessing import HashedCrossing\n",
    "\n",
    "logging.info(tf.version.VERSION)\n",
    "\n",
    "CSV_COLUMNS = [\n",
    "    \"fare_amount\",\n",
    "    \"pickup_datetime\",\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"passenger_count\",\n",
    "    \"key\",\n",
    "]\n",
    "\n",
    "LABEL_COLUMN = \"fare_amount\"\n",
    "DEFAULTS = [[0.0], [\"na\"], [0.0], [0.0], [0.0], [0.0], [0.0], [\"na\"]]\n",
    "UNWANTED_COLS = [\"pickup_datetime\", \"key\"]\n",
    "\n",
    "INPUT_COLS = [\n",
    "    c for c in CSV_COLUMNS if c != LABEL_COLUMN and c not in UNWANTED_COLS\n",
    "]\n",
    "\n",
    "def features_and_labels(row_data):\n",
    "    for unwanted_col in UNWANTED_COLS:\n",
    "        row_data.pop(unwanted_col)\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "    return row_data, label\n",
    "\n",
    "\n",
    "def load_dataset(pattern, batch_size, num_repeat):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_pattern=pattern,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_COLUMNS,\n",
    "        column_defaults=DEFAULTS,\n",
    "        num_epochs=num_repeat,\n",
    "        shuffle_buffer_size=1000000,\n",
    "    )\n",
    "    return dataset.map(features_and_labels)\n",
    "\n",
    "\n",
    "def create_train_dataset(pattern, batch_size):\n",
    "    dataset = load_dataset(pattern, batch_size, num_repeat=None)\n",
    "    return dataset.prefetch(1)\n",
    "\n",
    "\n",
    "def create_eval_dataset(pattern, batch_size):\n",
    "    dataset = load_dataset(pattern, batch_size, num_repeat=1)\n",
    "    return dataset.prefetch(1)\n",
    "\n",
    "\n",
    "def euclidean(params):\n",
    "    lon1, lat1, lon2, lat2 = params\n",
    "    londiff = lon2 - lon1\n",
    "    latdiff = lat2 - lat1\n",
    "    return tf.sqrt(londiff * londiff + latdiff * latdiff)\n",
    "\n",
    "\n",
    "def scale_longitude(lon_column):\n",
    "    return (lon_column + 78) / 8.0\n",
    "\n",
    "\n",
    "def scale_latitude(lat_column):\n",
    "    return (lat_column - 37) / 8.0\n",
    "\n",
    "\n",
    "def transform(inputs, nbuckets):\n",
    "    transformed = {}\n",
    "\n",
    "    transformed[\"scaled_plon\"] = Lambda(scale_longitude, name=\"scale_plon\")(\n",
    "        inputs[\"pickup_longitude\"]\n",
    "    )\n",
    "    transformed[\"scaled_dlon\"] = Lambda(scale_longitude, name=\"scale_dlon\")(\n",
    "        inputs[\"dropoff_longitude\"]\n",
    "    )\n",
    "\n",
    "    transformed[\"scaled_plat\"] = Lambda(scale_latitude, name=\"scale_plat\")(\n",
    "        inputs[\"pickup_latitude\"]\n",
    "    )\n",
    "    transformed[\"scaled_dlat\"] = Lambda(scale_latitude, name=\"scale_dlat\")(\n",
    "        inputs[\"dropoff_latitude\"]\n",
    "    )\n",
    "\n",
    "    transformed[\"euclidean_distance\"] = Lambda(euclidean, name=\"euclidean\")(\n",
    "        [\n",
    "            inputs[\"pickup_longitude\"],\n",
    "            inputs[\"pickup_latitude\"],\n",
    "            inputs[\"dropoff_longitude\"],\n",
    "            inputs[\"dropoff_latitude\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    latbuckets = np.linspace(start=0.0, stop=1.0, num=nbuckets).tolist()\n",
    "    lonbuckets = np.linspace(start=0.0, stop=1.0, num=nbuckets).tolist()\n",
    "\n",
    "    plon = Discretization(lonbuckets, name=\"plon_bkt\")(\n",
    "        transformed[\"scaled_plon\"]\n",
    "    )\n",
    "    plat = Discretization(latbuckets, name=\"plat_bkt\")(\n",
    "        transformed[\"scaled_plat\"]\n",
    "    )\n",
    "    dlon = Discretization(lonbuckets, name=\"dlon_bkt\")(\n",
    "        transformed[\"scaled_dlon\"]\n",
    "    )\n",
    "    dlat = Discretization(latbuckets, name=\"dlat_bkt\")(\n",
    "        transformed[\"scaled_dlat\"]\n",
    "    )\n",
    "\n",
    "    p_fc = HashedCrossing(num_bins=nbuckets * nbuckets, name=\"p_fc\")(\n",
    "        (plon, plat)\n",
    "    )\n",
    "    d_fc = HashedCrossing(num_bins=nbuckets * nbuckets, name=\"d_fc\")(\n",
    "        (dlon, dlat)\n",
    "    )\n",
    "    pd_fc = HashedCrossing(num_bins=nbuckets**4, name=\"pd_fc\")((p_fc, d_fc))\n",
    "\n",
    "    transformed[\"pd_embed\"] = Flatten()(\n",
    "        Embedding(input_dim=nbuckets**4, output_dim=10, name=\"pd_embed\")(\n",
    "            pd_fc\n",
    "        )\n",
    "    )\n",
    "\n",
    "    transformed[\"passenger_count\"] = inputs[\"passenger_count\"]\n",
    "\n",
    "    return transformed\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "def build_dnn_model(nbuckets, nnsize, lr):\n",
    "    inputs = {\n",
    "        colname: Input(name=colname, shape=(1,), dtype=\"float32\")\n",
    "        for colname in INPUT_COLS\n",
    "    }\n",
    "\n",
    "    transformed = transform(inputs, nbuckets)\n",
    "    dnn_inputs = Concatenate()(transformed.values())\n",
    "\n",
    "    x = dnn_inputs\n",
    "    for layer, nodes in enumerate(nnsize):\n",
    "        x = Dense(nodes, activation=\"relu\", name=f\"h{layer}\")(x)\n",
    "    output = Dense(1, name=\"fare\")(x)\n",
    "\n",
    "    model = models.Model(inputs, output)\n",
    "    lr_optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer=lr_optimizer, loss=\"mse\", metrics=[rmse, \"mse\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_and_evaluate(hparams):\n",
    "    batch_size = hparams[\"batch_size\"]\n",
    "    nbuckets = hparams[\"nbuckets\"]\n",
    "    lr = hparams[\"lr\"]\n",
    "    nnsize = [int(s) for s in hparams[\"nnsize\"].split()]\n",
    "    eval_data_path = hparams[\"eval_data_path\"]\n",
    "    num_evals = hparams[\"num_evals\"]\n",
    "    num_examples_to_train_on = hparams[\"num_examples_to_train_on\"]\n",
    "    output_dir = hparams[\"output_dir\"]\n",
    "    train_data_path = hparams[\"train_data_path\"]\n",
    "\n",
    "    model_export_path = os.path.join(output_dir, \"savedmodel\")\n",
    "    checkpoint_path = os.path.join(output_dir, \"checkpoints\")\n",
    "    tensorboard_path = os.path.join(output_dir, \"tensorboard\")\n",
    "\n",
    "    if tf.io.gfile.exists(output_dir):\n",
    "        tf.io.gfile.rmtree(output_dir)\n",
    "\n",
    "    model = build_dnn_model(nbuckets, nnsize, lr)\n",
    "    logging.info(model.summary())\n",
    "\n",
    "    trainds = create_train_dataset(train_data_path, batch_size)\n",
    "    evalds = create_eval_dataset(eval_data_path, batch_size)\n",
    "\n",
    "    steps_per_epoch = num_examples_to_train_on // (batch_size * num_evals)\n",
    "\n",
    "    checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "        checkpoint_path, save_weights_only=True, verbose=1\n",
    "    )\n",
    "    tensorboard_cb = callbacks.TensorBoard(tensorboard_path, histogram_freq=1)\n",
    "\n",
    "    history = model.fit(\n",
    "        trainds,\n",
    "        validation_data=evalds,\n",
    "        epochs=num_evals,\n",
    "        steps_per_epoch=max(1, steps_per_epoch),\n",
    "        verbose=2,\n",
    "        callbacks=[checkpoint_cb, tensorboard_cb],\n",
    "    )\n",
    "\n",
    "    model.save(model_export_path)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8ec97b-ad3b-4bc6-9cfb-b9e8b2dd38c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " pickup_longitude (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dropoff_longitude (InputLayer)  [(None, 1)]         0           []                               \n",
      "                                                                                                  \n",
      " pickup_latitude (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dropoff_latitude (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " scale_plon (Lambda)            (None, 1)            0           ['pickup_longitude[0][0]']       \n",
      "                                                                                                  \n",
      " scale_dlon (Lambda)            (None, 1)            0           ['dropoff_longitude[0][0]']      \n",
      "                                                                                                  \n",
      " scale_plat (Lambda)            (None, 1)            0           ['pickup_latitude[0][0]']        \n",
      "                                                                                                  \n",
      " scale_dlat (Lambda)            (None, 1)            0           ['dropoff_latitude[0][0]']       \n",
      "                                                                                                  \n",
      " plon_bkt (Discretization)      (None, 1)            0           ['scale_plon[0][0]']             \n",
      "                                                                                                  \n",
      " plat_bkt (Discretization)      (None, 1)            0           ['scale_plat[0][0]']             \n",
      "                                                                                                  \n",
      " dlon_bkt (Discretization)      (None, 1)            0           ['scale_dlon[0][0]']             \n",
      "                                                                                                  \n",
      " dlat_bkt (Discretization)      (None, 1)            0           ['scale_dlat[0][0]']             \n",
      "                                                                                                  \n",
      " p_fc (HashedCrossing)          (None, 1)            0           ['plon_bkt[0][0]',               \n",
      "                                                                  'plat_bkt[0][0]']               \n",
      "                                                                                                  \n",
      " d_fc (HashedCrossing)          (None, 1)            0           ['dlon_bkt[0][0]',               \n",
      "                                                                  'dlat_bkt[0][0]']               \n",
      "                                                                                                  \n",
      " pd_fc (HashedCrossing)         (None, 1)            0           ['p_fc[0][0]',                   \n",
      "                                                                  'd_fc[0][0]']                   \n",
      "                                                                                                  \n",
      " pd_embed (Embedding)           (None, 1, 10)        100000      ['pd_fc[0][0]']                  \n",
      "                                                                                                  \n",
      " euclidean (Lambda)             (None, 1)            0           ['pickup_longitude[0][0]',       \n",
      "                                                                  'pickup_latitude[0][0]',        \n",
      "                                                                  'dropoff_longitude[0][0]',      \n",
      "                                                                  'dropoff_latitude[0][0]']       \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 10)           0           ['pd_embed[0][0]']               \n",
      "                                                                                                  \n",
      " passenger_count (InputLayer)   [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16)           0           ['scale_plon[0][0]',             \n",
      "                                                                  'scale_dlon[0][0]',             \n",
      "                                                                  'scale_plat[0][0]',             \n",
      "                                                                  'scale_dlat[0][0]',             \n",
      "                                                                  'euclidean[0][0]',              \n",
      "                                                                  'flatten[0][0]',                \n",
      "                                                                  'passenger_count[0][0]']        \n",
      "                                                                                                  \n",
      " h0 (Dense)                     (None, 32)           544         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " h1 (Dense)                     (None, 8)            264         ['h0[0][0]']                     \n",
      "                                                                                                  \n",
      " fare (Dense)                   (None, 1)            9           ['h1[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 100,817\n",
      "Trainable params: 100,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 22:59:51.496642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-18 22:59:51.497627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-18 22:59:53.284057: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-18 22:59:53.284414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to babyweight-trained/checkpoints\n",
      "1/1 - 3s - loss: 316.5316 - rmse: 17.7913 - mse: 316.5316 - val_loss: 248.1806 - val_rmse: 15.2128 - val_mse: 248.1806 - 3s/epoch - 3s/step\n",
      "Epoch 2/5\n",
      "\n",
      "Epoch 2: saving model to babyweight-trained/checkpoints\n",
      "1/1 - 0s - loss: 424.0381 - rmse: 20.5922 - mse: 424.0381 - val_loss: 247.9235 - val_rmse: 15.2091 - val_mse: 247.9235 - 245ms/epoch - 245ms/step\n",
      "Epoch 3/5\n",
      "\n",
      "Epoch 3: saving model to babyweight-trained/checkpoints\n",
      "1/1 - 0s - loss: 287.3563 - rmse: 16.9516 - mse: 287.3563 - val_loss: 247.6700 - val_rmse: 15.1065 - val_mse: 247.6700 - 263ms/epoch - 263ms/step\n",
      "Epoch 4/5\n",
      "\n",
      "Epoch 4: saving model to babyweight-trained/checkpoints\n",
      "1/1 - 0s - loss: 115.9618 - rmse: 10.7686 - mse: 115.9618 - val_loss: 247.4210 - val_rmse: 15.1356 - val_mse: 247.4210 - 254ms/epoch - 254ms/step\n",
      "Epoch 5/5\n",
      "\n",
      "Epoch 5: saving model to babyweight-trained/checkpoints\n",
      "1/1 - 0s - loss: 118.4053 - rmse: 10.8814 - mse: 118.4053 - val_loss: 247.1783 - val_rmse: 15.1578 - val_mse: 247.1783 - 237ms/epoch - 237ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 22:59:55.548141: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dropoff_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node dropoff_longitude}}]]\n",
      "2023-05-18 22:59:55.548292: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pickup_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node pickup_longitude}}]]\n",
      "2023-05-18 22:59:55.592993: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dropoff_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node dropoff_longitude}}]]\n",
      "2023-05-18 22:59:55.593146: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pickup_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node pickup_longitude}}]]\n",
      "2023-05-18 22:59:55.632894: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype int64 and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-18 22:59:55.637627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype int64 and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-18 22:59:55.642505: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype int64 and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-18 22:59:55.703113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_2' with dtype float and shape [?,1]\n",
      "\t [[{{node inputs_2}}]]\n",
      "2023-05-18 22:59:55.703259: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-18 22:59:55.716361: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_2' with dtype float and shape [?,1]\n",
      "\t [[{{node inputs_2}}]]\n",
      "2023-05-18 22:59:55.716484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,1]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-18 22:59:55.821386: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dropoff_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node dropoff_longitude}}]]\n",
      "2023-05-18 22:59:55.821517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'pickup_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node pickup_longitude}}]]\n",
      "2023-05-18 22:59:55.878340: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_dropoff_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node inputs_dropoff_longitude}}]]\n",
      "2023-05-18 22:59:55.878473: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_pickup_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node inputs_pickup_longitude}}]]\n",
      "2023-05-18 22:59:55.892828: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_dropoff_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node inputs_dropoff_longitude}}]]\n",
      "2023-05-18 22:59:55.892949: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_pickup_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node inputs_pickup_longitude}}]]\n",
      "2023-05-18 22:59:56.093814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype int64 and shape [?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-05-18 22:59:56.109543: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype int64 and shape [?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "2023-05-18 22:59:56.125479: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs_0' with dtype int64 and shape [?,1]\n",
      "\t [[{{node inputs_0}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
      "2023-05-18 22:59:56.299874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_dropoff_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node serving_default_dropoff_longitude}}]]\n",
      "2023-05-18 22:59:56.299997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'serving_default_pickup_longitude' with dtype float and shape [?,1]\n",
      "\t [[{{node serving_default_pickup_longitude}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: babyweight-trained/savedmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: babyweight-trained/savedmodel/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c6afcfbe0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = dict(\n",
    "    batch_size=32,\n",
    "    nnsize=\"32 8\",\n",
    "    nbuckets=10,\n",
    "    lr=0.001,\n",
    "    num_evals=5,\n",
    "    num_examples_to_train_on=100,\n",
    "    output_dir='babyweight-trained',\n",
    "    train_data_path='../datasets/taxi-train.csv',\n",
    "    eval_data_path='../datasets/taxi-valid.csv'\n",
    ")\n",
    "train_and_evaluate(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01372f5b-2529-4ecf-9a99-4ac5e61912c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab630c73-a558-4d23-b62f-69d486b06f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a03436f0445e823a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a03436f0445e823a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --host=0.0.0.0 --port=6006 --logdir babyweight-trained/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017188a-712e-4dec-83a9-b69e8e8c2970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
