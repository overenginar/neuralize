{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3347b276-b33e-4f6d-b524-cec07cf726a7",
   "metadata": {},
   "source": [
    "### Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741b2a4d-a870-4541-8de7-7aab8b6f518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 10:03:37.162378: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-19 10:03:37.490528: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-19 10:03:37.492329: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 10:03:39.291535: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Dot,\n",
    "    Dropout,\n",
    "    Embedding,\n",
    "    Input,\n",
    "    Lambda,\n",
    "    Layer,\n",
    "    Masking,\n",
    "    SimpleRNN,\n",
    "    Softmax,\n",
    ")\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514923a2-8e4b-4e40-9a08-d22f0ec7181b",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf8718a-5836-4f00-a0dd-e2d0fd41c106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>c_id</th>\n",
       "      <th>start_word</th>\n",
       "      <th>end_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What types of wisdom did Mackintosh say Burke ...</td>\n",
       "      <td>Burke's Reflections sparked a pamphlet war. Th...</td>\n",
       "      <td>political and moral</td>\n",
       "      <td>10068</td>\n",
       "      <td>127</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many monasteries were destroyed during the...</td>\n",
       "      <td>After the Dalai Lama's government fled to Dhar...</td>\n",
       "      <td>6,000</td>\n",
       "      <td>12309</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In what year did Time magazine choose Seattle ...</td>\n",
       "      <td>Seattle is home to the University of Washingto...</td>\n",
       "      <td>2001</td>\n",
       "      <td>7465</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What types of wisdom did Mackintosh say Burke ...   \n",
       "1  How many monasteries were destroyed during the...   \n",
       "2  In what year did Time magazine choose Seattle ...   \n",
       "\n",
       "                                             context                 text  \\\n",
       "0  Burke's Reflections sparked a pamphlet war. Th...  political and moral   \n",
       "1  After the Dalai Lama's government fled to Dhar...                6,000   \n",
       "2  Seattle is home to the University of Washingto...                 2001   \n",
       "\n",
       "    c_id  start_word  end_word  \n",
       "0  10068         127       129  \n",
       "1  12309          52        52  \n",
       "2   7465         122       122  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./datasets/squad10k.csv\")\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412c06bd-3610-4c03-a479-9db9e96908f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answer1</th>\n",
       "      <th>answer2</th>\n",
       "      <th>answer3</th>\n",
       "      <th>answer4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what country is Normandy located?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When were the Normans in Normandy?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>in the 10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "      <td>10th and 11th centuries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From which countries did the Norse originate?</td>\n",
       "      <td>The Normans (Norman: Nourmands; French: Norman...</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "      <td>Denmark, Iceland and Norway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        question  \\\n",
       "0           In what country is Normandy located?   \n",
       "1             When were the Normans in Normandy?   \n",
       "2  From which countries did the Norse originate?   \n",
       "\n",
       "                                             context  \\\n",
       "0  The Normans (Norman: Nourmands; French: Norman...   \n",
       "1  The Normans (Norman: Nourmands; French: Norman...   \n",
       "2  The Normans (Norman: Nourmands; French: Norman...   \n",
       "\n",
       "                       answer1                         answer2  \\\n",
       "0                       France                          France   \n",
       "1      10th and 11th centuries  in the 10th and 11th centuries   \n",
       "2  Denmark, Iceland and Norway     Denmark, Iceland and Norway   \n",
       "\n",
       "                       answer3                      answer4  \n",
       "0                       France                       France  \n",
       "1      10th and 11th centuries      10th and 11th centuries  \n",
       "2  Denmark, Iceland and Norway  Denmark, Iceland and Norway  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"./datasets/squadtest1k.csv\")\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2311e0c-4a71-4a00-9a59-062b13c43699",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0ec6901-7439-4a29-9590-6665f8a8d8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 10:03:42.000696: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 498570752 exceeds 10% of free system memory.\n",
      "2023-05-19 10:03:42.694488: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'sentences' with dtype string and shape [?]\n",
      "\t [[{{node sentences}}]]\n"
     ]
    }
   ],
   "source": [
    "paragraphs = []\n",
    "questions = []\n",
    "embed = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
    "\n",
    "for text in train.context:\n",
    "    words = np.array(text_to_word_sequence(text))\n",
    "    paragraphs.append(embed(tf.constant(words)))\n",
    "\n",
    "for text in train.question:\n",
    "    words = np.array(text_to_word_sequence(text))\n",
    "    questions.append(embed(tf.constant(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878f2953-8612-4b04-b3ba-76356bc3cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_paragraphs = pad_sequences(paragraphs, padding=\"post\", dtype=\"float32\")\n",
    "padded_questions = pad_sequences(questions, padding=\"post\", dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0586d1a-0980-4234-b163-b77a680aa959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Padded Embedded Paragraphs:  (10000, 498, 128)\n",
      "Shape of the Padded Embedded Questions:  (10000, 31, 128)\n",
      "i.e. (Batch Size, Sequence Length, Embed Dimension)\n",
      "Shape of the Y Train set for Start Word:  (10000,)\n",
      "Shape of the Y Train set for End Word:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "batch_size = np.shape(padded_paragraphs)[0]\n",
    "max_paragraph_length = np.shape(padded_paragraphs)[1]\n",
    "max_question_length = np.shape(padded_questions)[1]\n",
    "embedding_dimension = np.shape(padded_paragraphs)[2]\n",
    "\n",
    "print(\"Shape of the Padded Embedded Paragraphs: \", np.shape(padded_paragraphs))\n",
    "print(\"Shape of the Padded Embedded Questions: \", np.shape(padded_questions))\n",
    "print(\"i.e. (Batch Size, Sequence Length, Embed Dimension)\")\n",
    "\n",
    "y_start_word = np.array(train.start_word)\n",
    "y_end_word = np.array(train.end_word)\n",
    "print(\"Shape of the Y Train set for Start Word: \", np.shape(y_start_word))\n",
    "print(\"Shape of the Y Train set for End Word: \", np.shape(y_end_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb299b-863f-46dd-8b3b-98d423c7ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    paragraphs_train,\n",
    "    paragraphs_val,\n",
    "    questions_train,\n",
    "    questions_val,\n",
    "    answer_start_train,\n",
    "    answer_start_val,\n",
    "    answer_end_train,\n",
    "    answer_end_val,\n",
    ") = train_test_split(\n",
    "    padded_paragraphs,\n",
    "    padded_questions,\n",
    "    y_start_word,\n",
    "    y_end_word,\n",
    "    test_size=0.1,\n",
    "    random_state=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86add05-ef33-47a4-9a2f-056e09705140",
   "metadata": {},
   "source": [
    "### Metrics and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb2a9c-2d32-4c66-b5a7-87f0e2e7d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(predicted_answer, true_answer):\n",
    "    truth = str(true_answer).replace(\"-\", \" \")\n",
    "    truth = \"\".join(token for token in truth if token not in string.punctuation)\n",
    "    return np.sum(str(predicted_answer).lower() == str(true_answer).lower())\n",
    "\n",
    "\n",
    "def f1_score(predicted_answer, true_answer):\n",
    "    predicted = text_to_word_sequence(str(predicted_answer))\n",
    "    truth = text_to_word_sequence(str(true_answer))\n",
    "    true_positive = [i for i in predicted if i in truth]\n",
    "    if len(true_positive) == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        precision = len(true_positive) / len(predicted)\n",
    "        recall = len(true_positive) / len(truth)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48dde338-371a-4040-82be-8ffbb7a7e508",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m paragraphs \u001b[38;5;241m=\u001b[39m \u001b[43mInput\u001b[49m(\n\u001b[1;32m      2\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(max_paragraph_length, embedding_dimension), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparagraphs_input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m paragraph \u001b[38;5;241m=\u001b[39m Masking(mask_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)(paragraphs)\n\u001b[1;32m      5\u001b[0m paragraph \u001b[38;5;241m=\u001b[39m GRU(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m      7\u001b[0m     return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglorot_normal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m )(paragraph)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "paragraphs = Input(\n",
    "    shape=(max_paragraph_length, embedding_dimension), name=\"paragraphs_input\"\n",
    ")\n",
    "paragraph = Masking(mask_value=0)(paragraphs)\n",
    "paragraph = GRU(\n",
    "    256,\n",
    "    return_sequences=True,\n",
    "    name=\"paragraph_out\",\n",
    "    kernel_regularizer=regularizers.l2(0.002),\n",
    "    kernel_initializer=\"glorot_normal\",\n",
    ")(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdbcc7d2-03d4-43b6-89dc-ceee82accab7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m questions \u001b[38;5;241m=\u001b[39m \u001b[43mInput\u001b[49m(\n\u001b[1;32m      2\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(max_question_length, embedding_dimension), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestions_input\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m question \u001b[38;5;241m=\u001b[39m Masking(mask_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)(questions)\n\u001b[1;32m      5\u001b[0m question \u001b[38;5;241m=\u001b[39m GRU(\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m      7\u001b[0m     return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglorot_normal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m )(question)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "questions = Input(\n",
    "    shape=(max_question_length, embedding_dimension), name=\"questions_input\"\n",
    ")\n",
    "question = Masking(mask_value=0)(questions)\n",
    "question = GRU(\n",
    "    256,\n",
    "    return_sequences=True,\n",
    "    name=\"question_gru\",\n",
    "    kernel_regularizer=regularizers.l2(0.002),\n",
    "    kernel_initializer=\"glorot_normal\",\n",
    ")(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dd3c09-b092-4754-aa48-319c26d78ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = Dense(1, activation=\"softmax\", name=\"weights\")(question)\n",
    "question = Dot(axes=1, name=\"question_out\")([weights, question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed3a99-2487-43c2-8995-d71dc1037e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_start = Dense(\n",
    "    256,\n",
    "    activation=\"linear\",\n",
    "    name=\"s1\",\n",
    "    use_bias=False,\n",
    "    kernel_regularizer=regularizers.l2(0.001),\n",
    ")(question)\n",
    "answer_start = Dot(axes=(2, 2), name=\"s2\")([paragraph, question_start])\n",
    "question_end = Dense(\n",
    "    256,\n",
    "    activation=\"linear\",\n",
    "    name=\"e1\",\n",
    "    use_bias=False,\n",
    "    kernel_regularizer=regularizers.l2(0.001),\n",
    ")(question)\n",
    "answer_end = Dot(axes=(2, 2), name=\"e2\")([paragraph, question_end])\n",
    "\n",
    "model = Model(\n",
    "    inputs=[paragraphs, questions], outputs=[answer_start, answer_end]\n",
    ")\n",
    "plot_model(model, to_file=\"Baseline.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606679ba-aa2a-49f0-962f-44824646c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "opt = tf.keras.optimizers.Adamax()\n",
    "sce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt, loss=[sce, sce], loss_weights=[1, 1], metrics=[[acc], [acc]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf558f4-f36c-4fcf-ae11-9cdda225311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=\"basemodel\",\n",
    "    frequency=\"epoch\",\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ef1e9-cd64-433c-9049-b1e3311bee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    [paragraphs_train, questions_train],\n",
    "    [answer_start_train, answer_end_train],\n",
    "    validation_data=(\n",
    "        [paragraphs_val, questions_val],\n",
    "        [answer_start_val, answer_end_val],\n",
    "    ),\n",
    "    epochs=1,\n",
    "    batch_size=64,\n",
    "    callbacks=[checkpoint],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085effa-1f45-4e06-bb50-40a704777c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"basemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963db4a5-8c75-4280-8e52-bd60f5c33354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masked_matrix(pred_start, pred_end):\n",
    "    # Creating the masked matrix of possible answers (where start < end < start 15)\n",
    "    masked_matrix = tf.matmul(pred_start, tf.transpose(pred_end, [0, 2, 1]))\n",
    "    i, j = np.meshgrid(\n",
    "        *map(np.arange, (masked_matrix.shape[1], masked_matrix.shape[2])),\n",
    "        indexing=\"ij\"\n",
    "    )\n",
    "    masked_matrix.mask = (i <= j) & (j < i + 15)\n",
    "    masked_matrix = np.where(masked_matrix.mask, masked_matrix, 0)\n",
    "    max_results = np.amax(masked_matrix, axis=(1, 2))\n",
    "    return masked_matrix, max_results\n",
    "\n",
    "\n",
    "def model_eval(pred):\n",
    "    pred_start = tf.exp(pred[0])\n",
    "    pred_end = tf.exp(pred[1])\n",
    "\n",
    "    masked_matrix, max_results = create_masked_matrix(pred_start, pred_end)\n",
    "    number_of_examples = masked_matrix.shape[0]\n",
    "\n",
    "    em = []\n",
    "    f1 = []\n",
    "\n",
    "    # Find the most probable answer for each question in the test set.\n",
    "    # We compare with the four human answers, and keep the max F1 and EM scores.\n",
    "    for k in range(number_of_examples):\n",
    "        result = np.where(masked_matrix[k] == max_results[k])\n",
    "        if result[1][0] < len(text_to_word_sequence(test.context[k])):\n",
    "            answer = np.array(text_to_word_sequence(test.context[k]))[\n",
    "                result[0][0] : result[1][0] + 1\n",
    "            ]\n",
    "        else:\n",
    "            answer = [\"-\"]\n",
    "\n",
    "        if result[0][0] != result[1][0] and result[1][0] < len(\n",
    "            text_to_word_sequence(test.context[k])\n",
    "        ):\n",
    "            answer = \" \".join(answer)\n",
    "        else:\n",
    "            answer = str(answer[0])\n",
    "        em_k = max(\n",
    "            exact_match(answer, test.answer1[k]),\n",
    "            exact_match(answer, test.answer2[k]),\n",
    "            exact_match(answer, test.answer3[k]),\n",
    "            exact_match(answer, test.answer4[k]),\n",
    "        )\n",
    "        f1_k = max(\n",
    "            f1_score(answer, test.answer1[k]),\n",
    "            f1_score(answer, test.answer2[k]),\n",
    "            f1_score(answer, test.answer3[k]),\n",
    "            f1_score(answer, test.answer4[k]),\n",
    "        )\n",
    "        em.append(em_k)\n",
    "        f1.append(f1_k)\n",
    "\n",
    "    print(\"Exact Match: \", np.round(np.mean(em), 3))\n",
    "    print(\"F1 Score: \", np.round(np.mean(f1), 3))\n",
    "\n",
    "    return (em, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2ddf7-291e-406d-9308-5de7f10a2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_test = []\n",
    "question_test = []\n",
    "embed = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")  # NNLM\n",
    "\n",
    "for text in test.context:\n",
    "    words = np.array(text_to_word_sequence(text))\n",
    "    paragraph_test.append(embed(tf.constant(words)))\n",
    "\n",
    "for text in test.question:\n",
    "    words = np.array(text_to_word_sequence(text))\n",
    "    question_test.append(embed(tf.constant(words)))\n",
    "\n",
    "p_test = pad_sequences(\n",
    "    paragraph_test, padding=\"post\", dtype=\"float32\", maxlen=max_paragraph_length\n",
    ")\n",
    "q_test = pad_sequences(\n",
    "    question_test, padding=\"post\", dtype=\"float32\", maxlen=max_question_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08e2c4-681e-41bc-bde7-3b7aaece6743",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict([p_test, q_test])\n",
    "print(\"**Results on Test Set:\")\n",
    "(em_model, f1_model) = model_eval(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391e38d-1d55-473c-b347-184c42c2b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = Input(\n",
    "    shape=(max_paragraph_length, embedding_dimension), name=\"par0\"\n",
    ")\n",
    "p = Masking(mask_value=0)(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df13f4-9726-45cb-b925-fe7132524401",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Bidirectional(\n",
    "    GRU(\n",
    "        128,\n",
    "        return_sequences=True,\n",
    "        name=\"par1\",\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "    ),\n",
    "    merge_mode=\"concat\",\n",
    ")(p)\n",
    "p = Dropout(0.15)(p)\n",
    "\n",
    "p = Bidirectional(\n",
    "    GRU(\n",
    "        64,\n",
    "        return_sequences=True,\n",
    "        name=\"par2\",\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "    ),\n",
    "    merge_mode=\"concat\",\n",
    ")(p)\n",
    "p = Dropout(0.15)(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f826fd-106f-414d-9b1f-153c8ab18934",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = Input(\n",
    "    shape=(max_question_length, embedding_dimension), name=\"ques0\"\n",
    ")\n",
    "q = Masking(mask_value=0)(questions)\n",
    "q = GRU(256, return_sequences=True, name=\"ques2\")(q)\n",
    "q = Dropout(0.15)(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e2ebd-ba7f-4643-b6fc-7002f835564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = Dense(1, activation=\"softmax\", name=\"weights\")(q)\n",
    "q = Dot(axes=1, name=\"ques3\")([weights, q])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad6b78-3893-47ff-99b2-7d327dbbb9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_start = Dense(\n",
    "    128,\n",
    "    activation=\"linear\",\n",
    "    name=\"s1\",\n",
    "    use_bias=False,\n",
    "    kernel_regularizer=regularizers.l2(0.002),\n",
    ")(q)\n",
    "answer_start = Dot(axes=(2, 2), name=\"s2\")([p, question_start])\n",
    "\n",
    "question_end = Dense(\n",
    "    128,\n",
    "    activation=\"linear\",\n",
    "    name=\"e1\",\n",
    "    use_bias=False,\n",
    "    kernel_regularizer=regularizers.l2(0.002),\n",
    ")(q)\n",
    "answer_end = Dot(axes=(2, 2), name=\"e2\")([p, question_end])\n",
    "# Output is = a probability vector (None, seq_pars, 1) for each\n",
    "\n",
    "# Model\n",
    "model = Model(\n",
    "    inputs=[paragraphs, questions], outputs=[answer_start, answer_end]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ee2e5-cd5c-42a6-bfd1-53671a8b3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masked_matrix_for_one(pred_start, pred_end):\n",
    "    # Creating the masked matrix of possible answers (where start < end < start 15)\n",
    "    masked_matrix = tf.matmul(pred_start, tf.transpose(pred_end))\n",
    "    i, j = np.meshgrid(*map(np.arange, (masked_matrix.shape)), indexing=\"ij\")\n",
    "    masked_matrix.mask = (i <= j) & (j < i + 15)\n",
    "    masked_matrix = np.where(masked_matrix.mask, masked_matrix, 0)\n",
    "    max_results = np.where(masked_matrix == np.amax(masked_matrix))\n",
    "    return masked_matrix, max_results\n",
    "\n",
    "\n",
    "# Function to get the result on the kth question\n",
    "def get_result(k, model=model, verbose=True):\n",
    "    paragraph = tf.expand_dims(p_test[k], 0)\n",
    "    question = tf.expand_dims(q_test[k], 0)\n",
    "    out = model([paragraph, question])\n",
    "    start = tf.exp(out[0][0])\n",
    "    end = tf.exp(out[1][0])\n",
    "\n",
    "    _, result = create_masked_matrix_for_one(start, end)\n",
    "\n",
    "    if result[1][0] < len(text_to_word_sequence(test.context[k])):\n",
    "        answer = np.array(text_to_word_sequence(test.context[k]))[\n",
    "            result[0][0] : result[1][0] + 1\n",
    "        ]\n",
    "    else:\n",
    "        answer = [\"-\"]\n",
    "\n",
    "    if result[0][0] != result[1][0] and result[1][0] < len(\n",
    "        text_to_word_sequence(test.context[k])\n",
    "    ):\n",
    "        answer = \" \".join(answer)\n",
    "    else:\n",
    "        answer = str(answer[0])\n",
    "    if verbose:\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        print(\"Question: \", test.question[k])\n",
    "        print(\"--------------------------------------------------------\")\n",
    "        print(\"Context: \")\n",
    "        print(test.context[k])\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"Model's answer: \", answer)\n",
    "    print(\"Human answers: \")\n",
    "    print(\n",
    "        test.answer1[k],\n",
    "        \" -- \",\n",
    "        test.answer2[k],\n",
    "        \" -- \",\n",
    "        test.answer3[k],\n",
    "        \" -- \",\n",
    "        test.answer4[k],\n",
    "    )\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\n",
    "        \"EM Score: \",\n",
    "        max(\n",
    "            exact_match(answer, test.answer1[k]),\n",
    "            exact_match(answer, test.answer2[k]),\n",
    "            exact_match(answer, test.answer3[k]),\n",
    "            exact_match(answer, test.answer4[k]),\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"F1 Score: \",\n",
    "        np.round(\n",
    "            max(\n",
    "                f1_score(answer, test.answer1[k]),\n",
    "                f1_score(answer, test.answer2[k]),\n",
    "                f1_score(answer, test.answer3[k]),\n",
    "                f1_score(answer, test.answer4[k]),\n",
    "            ),\n",
    "            3,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b844b84-f7f2-4890-9f45-6168fed41249",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_result(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9800d-7280-4627-99cf-626b59ceede2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
