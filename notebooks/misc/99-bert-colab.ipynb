{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e3ae9-ce83-4158-9ff7-0389ad51cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6eff8-8003-4b30-a040-fc77c004e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /home/jupyter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafae50-bbd0-4f78-8a9b-c8d9b54cf492",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "path = \"/home/jupyter/\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    \"aclImdb_v1.tar.gz\", url, untar=True, cache_dir=path, cache_subdir=\"\"\n",
    ")\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "\n",
    "remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f8cd02-9c60-48b0-91d1-ebd2c48da893",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    path + \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    path + \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "    path + \"aclImdb/test\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6682799-0bf7-4702-96e1-e9b59193c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        print(f\"Review: {text_batch.numpy()[i]}\")\n",
    "        label = label_batch.numpy()[i]\n",
    "        print(f\"Label : {label} ({class_names[label]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b60ba5-d1a8-4a9d-87a3-1947ec5c61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfhub_handle_encoder = (\n",
    "    \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    ")\n",
    "\n",
    "tfhub_handle_preprocess = (\n",
    "    \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    ")\n",
    "\n",
    "print(f\"BERT model selected           : {tfhub_handle_encoder}\")\n",
    "print(f\"Preprocess model auto-selected: {tfhub_handle_preprocess}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de50a44-a2c4-400a-9ea6-0b4496305b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0df496-8238-426a-9e14-0ea0a5796939",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = [\"this is such an amazing movie!\"]\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f\"Keys       : {list(text_preprocessed.keys())}\")\n",
    "\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca3bbc-708f-4816-b682-475e76dba603",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6fe08-24d4-400a-8300-91b3342c3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f\"Loaded BERT: {tfhub_handle_encoder}\")\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0380ed7-8265-4c4d-a56a-f313bc1b70c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model(dropout_rate=0.1):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"text\")\n",
    "    preprocessing_layer = hub.KerasLayer(\n",
    "        tfhub_handle_preprocess, name=\"preprocessing\"\n",
    "    )\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(\n",
    "        tfhub_handle_encoder, trainable=True, name=\"BERT_encoder\"\n",
    "    )\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs[\"pooled_output\"]\n",
    "    net = tf.keras.layers.Dropout(dropout_rate)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"classifier\")(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "\n",
    "dropout_rate = 0.15\n",
    "classifier_model = build_classifier_model(dropout_rate)\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(bert_raw_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c13bf-159d-4953-9b18-2fff371917af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522d0b5-c7e2-4245-94e4-a6c36ae002d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "metrics = tf.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2a6ae-f1cc-422d-bbd5-138d95b427f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1 * num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "optimizer = optimization.create_optimizer(\n",
    "    init_lr=init_lr,\n",
    "    num_train_steps=num_train_steps,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    optimizer_type=\"adamw\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af39a28-92a3-48ed-a724-b5ab20025e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d6068e-1bcb-4f32-ab25-92fd732e4bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training model with {tfhub_handle_encoder}\")\n",
    "history = classifier_model.fit(\n",
    "    x=train_ds, validation_data=val_ds, epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2eda0-7818-4e85-a5d8-e7f3b20a2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = classifier_model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a005efa-3228-469c-9346-ff801115df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict[\"binary_accuracy\"]\n",
    "val_acc = history_dict[\"val_binary_accuracy\"]\n",
    "loss = history_dict[\"loss\"]\n",
    "val_loss = history_dict[\"val_loss\"]\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, loss, \"r\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, \"r\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78c322-fa62-49da-ac17-37e282ce0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"imdb\"\n",
    "saved_model_path = \"./{}_bert\".format(dataset_name.replace(\"/\", \"_\"))\n",
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "EXPORT_PATH = os.path.join(saved_model_path, TIMESTAMP)\n",
    "\n",
    "classifier_model.save(EXPORT_PATH, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3a6e5a-b553-40c0-835b-1653c6d95721",
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_model = tf.saved_model.load(EXPORT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6ec9f-888d-4037-a597-538720dcc03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "    result_for_printing = [\n",
    "        f\"input: {inputs[i]:<30} : score: {results[i][0]:.6f}\"\n",
    "        for i in range(len(inputs))\n",
    "    ]\n",
    "    print(*result_for_printing, sep=\"\\n\")\n",
    "    print()\n",
    "\n",
    "\n",
    "examples = [\n",
    "    \"this is such an amazing movie!\",  # this is the same sentence tried earlier\n",
    "    \"The movie was great!\",\n",
    "    \"The movie was meh.\",\n",
    "    \"The movie was okish.\",\n",
    "    \"The movie was terrible...\",\n",
    "]\n",
    "\n",
    "reloaded_results = reloaded_model(tf.constant(examples))\n",
    "original_results = classifier_model(tf.constant(examples))\n",
    "\n",
    "print(\"Results from the saved model:\")\n",
    "print_my_examples(examples, reloaded_results)\n",
    "print(\"Results from the model in memory:\")\n",
    "print_my_examples(examples, original_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6850f0ef-5547-4ae4-b12f-ee2e762182e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_results = reloaded_model.signatures[\"serving_default\"](\n",
    "    tf.constant(examples)\n",
    ")\n",
    "\n",
    "serving_results = serving_results[\"classifier\"]\n",
    "\n",
    "print_my_examples(examples, serving_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7ba1a-8c04-4962-9f41-aae22b4cb2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def serving_default \\\n",
    "    --dir {EXPORT_PATH}\n",
    "\n",
    "!find {EXPORT_PATH}\n",
    "os.environ['EXPORT_PATH'] = EXPORT_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
